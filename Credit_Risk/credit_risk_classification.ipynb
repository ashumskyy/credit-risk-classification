{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "lending_df = pd.read_csv(Path(\"Resources/lending_data.csv\"))\n",
    "# Review the DataFrame\n",
    "lending_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "\n",
    "# Separate the y variable, the labels\n",
    "y = lending_df[\"loan_status\"]\n",
    "# Separate the X variable, the features\n",
    "X = lending_df.drop(columns=\"loan_status\", axis=1)\n",
    "\n",
    "# y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: loan_status, dtype: int64 (77536,)\n"
     ]
    }
   ],
   "source": [
    "# Review the y variable Series\n",
    "print(y[:5], y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
      "0    10700.0          7.672            52800        0.431818                5   \n",
      "1     8400.0          6.692            43600        0.311927                3   \n",
      "2     9000.0          6.963            46100        0.349241                3   \n",
      "3    10700.0          7.664            52700        0.430740                5   \n",
      "4    10800.0          7.698            53000        0.433962                5   \n",
      "\n",
      "   derogatory_marks  total_debt  \n",
      "0                 1       22800  \n",
      "1                 0       13600  \n",
      "2                 0       16100  \n",
      "3                 1       22700  \n",
      "4                 1       23000   (77536, 7)\n"
     ]
    }
   ],
   "source": [
    "# Review the X variable DataFrame\n",
    "print(X[:5], X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the balance of the labels variable (`y`) by using the `value_counts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75036\n",
       "1     2500\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y_value_count = y.value_counts()\n",
    "y_value_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_learn module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500, random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "lr_model = LogisticRegression(solver='lbfgs', max_iter=500, random_state=1)\n",
    "# Fit the model using training data\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using the testing data\n",
    "training_prediction = lr_model.predict(X_train)\n",
    "test_prediction = lr_model.predict(X_test)\n",
    "# result = pd.DataFrame({\"Predictions\": prediction, \"Actual\": y_test}).reset_index(drop=True)\n",
    "# result.head(10)\n",
    "max(lr_model.n_iter_)\n",
    "\n",
    "for x in lr_model.n_iter_:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy score of the model is: 0.9520479254722232\n",
      "0.9918489475856377\n"
     ]
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model\n",
    "print(f\"The balanced accuracy score of the model is: {balanced_accuracy_score(y_test, test_prediction)}\")\n",
    "print(accuracy_score(y_test, test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Matrix:\n",
      "[[55994   277]\n",
      " [  181  1700]]\n",
      "Test Matrix:\n",
      "[[18663   102]\n",
      " [   56   563]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "training_matrix = confusion_matrix(y_train, training_prediction)\n",
    "test_matrix = confusion_matrix(y_test, test_prediction)\n",
    "print(\"Train Matrix:\")\n",
    "print(training_matrix)\n",
    "print(\"Test Matrix:\")\n",
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56271\n",
      "           1       0.86      0.90      0.88      1881\n",
      "\n",
      "    accuracy                           0.99     58152\n",
      "   macro avg       0.93      0.95      0.94     58152\n",
      "weighted avg       0.99      0.99      0.99     58152\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.85      0.91      0.88       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.95      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "train_classification_report = classification_report(y_train, training_prediction)\n",
    "print(\"Train Classification Report:\")\n",
    "print(train_classification_report)\n",
    "test_classification_report = classification_report(y_test, test_prediction)\n",
    "print(\"Test Classification Report\")\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** Based on the Confusion Matrices and the Classification Reports, we can say, the logistic regression model performed well in predicting both the 0 (healthy loan) and 1 (high-risk loan) labels. The model achieved an f1-score of 1.00 in predicting the 0 label, indicating perfect precision and recall. For the 1 label, the model achieved an f1-score of 0.88, indicating good performance but slightly lower than that of the 0 label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomOverSampler module form imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the random oversampler model\n",
    "# # Assign a random_state parameter of 1 to the model\n",
    "oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "X_test_resampled, y_test_resampled = oversampler.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in y_train_resampled: 5980\n",
      "Number of distinct values in y_test_resampled: 4527\n"
     ]
    }
   ],
   "source": [
    "# Count the distinct values of the resampled labels data\n",
    "unique_labels_tr = np.unique(X_train_resampled)\n",
    "unique_labels_te = np.unique(X_test_resampled)\n",
    "print(\"Number of distinct values in y_train_resampled:\", len(unique_labels_tr))\n",
    "print(\"Number of distinct values in y_test_resampled:\", len(unique_labels_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "lr_model_2 = LogisticRegression(solver='lbfgs', max_iter=500, random_state=1)\n",
    "# Fit the model using the resampled training data\n",
    "lr_model_2.fit(X_train_resampled, y_train_resampled)\n",
    "# Make a prediction using the testing data\n",
    "training_prediction_2 = lr_model_2.predict(X_train_resampled)\n",
    "test_prediction_2 = lr_model_2.predict(X_test_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy score of the test model is: 0.9938715694111377\n",
      "The accuracy score of the test model is: 0.9938715694111377\n"
     ]
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model \n",
    "print(f\"The balanced accuracy score of the test model is: {balanced_accuracy_score(y_test_resampled, test_prediction_2)}\")\n",
    "print(f\"The accuracy score of the test model is: {accuracy_score(y_test_resampled, test_prediction_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Matrix:\n",
      "[[55964   307]\n",
      " [  286 55985]]\n",
      "Test Matrix:\n",
      "[[18649   116]\n",
      " [  114 18651]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "training_matrix_2 = confusion_matrix(y_train_resampled, training_prediction_2)\n",
    "test_matrix_2 = confusion_matrix(y_test_resampled, test_prediction_2)\n",
    "print(\"Train Matrix:\")\n",
    "print(training_matrix_2)\n",
    "print(\"Test Matrix:\")\n",
    "print(test_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     56271\n",
      "           1       0.99      0.99      0.99     56271\n",
      "\n",
      "    accuracy                           0.99    112542\n",
      "   macro avg       0.99      0.99      0.99    112542\n",
      "weighted avg       0.99      0.99      0.99    112542\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18765\n",
      "           1       0.99      0.99      0.99     18765\n",
      "\n",
      "    accuracy                           0.99     37530\n",
      "   macro avg       0.99      0.99      0.99     37530\n",
      "weighted avg       0.99      0.99      0.99     37530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "train_classification_report_2 = classification_report(y_train_resampled, training_prediction_2)\n",
    "print(\"Train Classification Report:\")\n",
    "print(train_classification_report_2)\n",
    "test_classification_report_2 = classification_report(y_test_resampled, test_prediction_2)\n",
    "print(\"Test Classification Report\")\n",
    "print(test_classification_report_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** The logistic regression model, trained with oversampled data, performed well in predicting both the `0` (healthy loan) and `1` (high-risk loan) labels, as evidenced by the high (`0.99`) precision, recall, and f1-scores for both classes in the training and testing classification reports. The confusion matrices show that the model predicted the majority of both 0 and 1 labels correctly in both the training and testing sets. \n",
    "\n",
    "Additionally, compared to the model trained on non-oversampled data, the oversampled model performed better in predicting high-risk loans, indicating its effectiveness in mitigating lending risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
